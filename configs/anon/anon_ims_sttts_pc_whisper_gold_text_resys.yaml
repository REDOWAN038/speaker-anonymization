lang: en

root_dir : .
data_dir: data
save_intermediate: true
save_output: true

results_dir: !ref <root_dir>/results_<lang>
models_dir:  !ref <root_dir>/models
vectors_dir: !ref <results_dir>/original_speaker_embeddings

force_compute_all: false
datasets: !include:../datasets.yaml   # we will select the correct subset of the datasets according to the chosen language at run time

pipeline: sttts

modules:
  asr:
    recognizer: null  # use gold text
    lang: !ref <lang>
    force_compute_recognition: false
    model_path: null
    utt_start_token: "~"
    utt_end_token: "~#"
    results_path: null

  speaker_embeddings:
    force_compute_extraction: false
    vec_type: style-embed
    emb_model_path: !ref <models_dir>/embedding_function.pt
    emb_level: utt   # possible: spk, utt
    extraction_results_path: !ref <results_dir>/original_speaker_embeddings/<modules[speaker_embeddings][vec_type]>_2.5_<modules[speaker_embeddings][emb_level]>-level

  prosody:
    extractor_type: ims
    lang: !ref <lang>
    aligner_model_path: !ref <models_dir>/aligner.pt
    extraction_results_path: !ref <results_dir>/original_prosody/ims_extractor_gold

  tts:
    synthesizer: ims
    lang: !ref <lang>
    force_compute_synthesis: false
    fastspeech_path: !ref <models_dir>/ToucanTTS_Meta.pt
    hifigan_path: !ref <models_dir>/Avocodo.pt
    embeddings_path: !ref <models_dir>/embedding_function.pt
    output_sr: 16000
    results_path: !ref <results_dir>/anon_speech/ims_sttts_multi_gold_text_resys