lang: en

root_dir : .
data_dir: data
save_intermediate: true
save_output: true

results_dir: !ref <root_dir>/results_<lang>
models_dir:  !ref <root_dir>/models
vectors_dir: !ref <results_dir>/original_speaker_embeddings

force_compute_all: false
datasets: !include:../datasets.yaml   # we will select the correct subset of the datasets according to the chosen language at run time

pipeline: sttts

modules:
  asr:
    recognizer: whisper
    lang: !ref <lang>
    force_compute_recognition: false
    model_path: !ref <models_dir>/whisper-large-v3
    utt_start_token: "~"
    utt_end_token: "~#"
    results_path: !ref <results_dir>/transcription/whisper-large-v3

  speaker_embeddings:
    anonymizer: ims
    force_compute_extraction: false
    force_compute_anonymization: false
    vec_type: style-embed
    emb_model_path: !ref <models_dir>/embedding_function.pt
    emb_level: spk   # possible: spk, utt
    anon_settings:   # possible: pool, random
      method: gan
      vectors_file: !ref <models_dir>/embedding_gan_generated_vectors.pt
      gan_model_path: !ref <models_dir>/embedding_gan.pt
      num_sampled: 5000
      sim_threshold: 0.7
    extraction_results_path: !ref <results_dir>/original_speaker_embeddings/<modules[speaker_embeddings][vec_type]>_2.5_<modules[speaker_embeddings][emb_level]>-level
    anon_results_path: !ref <results_dir>/anon_speaker_embeddings/<modules[speaker_embeddings][vec_type]>_2.5_<modules[speaker_embeddings][emb_level]>-level

  prosody:
    extractor_type: ims
    lang: !ref <lang>
    aligner_model_path: !ref <models_dir>/aligner.pt
    extraction_results_path: !ref <results_dir>/original_prosody/ims_extractor

  tts:
    synthesizer: ims
    lang: !ref <lang>
    force_compute_synthesis: false
    fastspeech_path: !ref <models_dir>/ToucanTTS_Meta.pt
    hifigan_path: !ref <models_dir>/Avocodo.pt
    embeddings_path: !ref <models_dir>/embedding_function.pt
    output_sr: 16000
    results_path: !ref <results_dir>/anon_speech/ims_sttts_multi